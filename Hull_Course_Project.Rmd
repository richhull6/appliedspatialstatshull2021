---
title: "Hull Course Project Applied Spatial Statistics Fall 2021"
output: html_notebook
---

## set working directory
```{r}
setwd("~/Indiana PhD/IU--Applied Spatial Statistics/Course_Project")
```

## install/load necessary packages
```{r}
# install/load data parsing packages
if(!require(dplyr)){install.packages("dplyr")}
library(dplyr)
if(!require(tidyr)){install.packages("tidyr")}
library(tidyr)
if(!require(data.table)){install.packages("data.table")}
library(data.table)
if(!require(stringr)){install.packages("stringr")}
library(stringr)
if(!require(lubridate)){install.packages("lubridate")}
library(lubridate)
# install/load map and raster packages
if(!require(picante)){install.packages("picante")}
library(picante)
if(!require(sf)){install.packages("sf")}
library(sf)
if(!require(tmap)){install.packages("tmap")}
library(tmap)
if(!require(rgdal)){install.packages("rgdal")}
library(rgdal)
if(!require(sp)){install.packages("sp")}
library(sp)
if(!require(raster)){install.packages("raster")}
library(raster)
# install/load exact multinomial test packages
if(!require(EMT)){install.packages("EMT")}
library(EMT)
if(!require(purrr)){install.packages("purrr")}
library(purrr)
```

### Part I: Parse plant occurrence data and calculate native species richness per county
## load raw plant occurrence data
```{r}
deam1 <- read.csv(file = "Deam_indiana_raw_data.csv", header = T, na.strings=c("","NA"))
```

## Combine genus and specificEpithet and then remove original columns
```{r}
deam1$speciesName <- paste(deam1$genus,deam1$specificEpithet)
deam2 <- subset(deam1, select = c(family, speciesName, recordedBy, eventDate, country, stateProvince, county, decimalLatitude, decimalLongitude))
```

## Remove data with no GPS coordinates or dates
```{r}
deam3 <- deam2 %>% drop_na()
```

## Remove data that are not identified to species (denoted by "NA") and remove hybrids
```{r}
deam4 <- deam3 %>% filter_all(all_vars(!grepl("NA", .)))
deam5 <- deam4 %>% filter_all(all_vars(!grepl("รณ", .)))
deam6 <- deam5 %>% filter_all(all_vars(!grepl("ร", .)))
```

## Correct county name spelling
```{r}
## Upload county name list
ctynames <- read.csv("ctynames.csv", header = TRUE, fileEncoding="UTF-8-BOM")
# Test for wrong county spellings
x <- deam6$county %in% ctynames$county
y <- data.frame(x)
z <- data.frame(which(grepl("FALSE", y$x)))
## If z contains data fix
## Correct county name spelling
deam6$county[deam6$county == "knox"] <- "Knox"
deam6$county[deam6$county == "gibson"] <- "Gibson"
deam6$county[deam6$county == "cass"] <- "Cass"
deam6$county[deam6$county == "pike"] <- "Pike"
deam6$county[deam6$county == "orange"] <- "Orange"
deam6$county[deam6$county == "grant"] <- "Grant"
deam6$county[deam6$county == "wayne"] <- "Wayne"
deam6$county[deam6$county == "jasper"] <- "Jasper"
deam6$county[deam6$county == "ELkhart"] <- "Elkhart"
deam6$county[deam6$county == "crawford"] <- "Crawford"
deam6$county[deam6$county == "La Porte"] <- "LaPorte"
# Test for wrong county spellings
x <- deam6$county %in% ctynames$county
y <- data.frame(x)
z <- data.frame(which(grepl("FALSE", y$x)))
```

## Correct Indiana name spelling
```{r}
# Correct indiana to Indiana
deam6$stateProvince[deam6$stateProvince == "indiana"] <- "Indiana"
```

## Correct species names against official list at: https://midwestherbaria.org/portal/checklists/checklist.php?clid=3510&pid=124&dynclid=0.
```{r}
## Upload county name list
indspecies <- read.csv("indspecies.csv", header = TRUE, fileEncoding="UTF-8-BOM")

# Test for wrong species spellings
x <- deam6$speciesName %in% indspecies$ScientificName
y <- data.frame(x)
z <- data.frame(which(grepl("FALSE", y$x)))

## Reassign unnaccepted names to their accepted synonyms

deam6$speciesName[deam6$speciesName == "Andropogon gerardii"] <- "Andropogon gerardi"

deam6$speciesName[deam6$speciesName == "Adicea deamii"] <- "Pilea pumila"

deam6$speciesName[deam6$speciesName == "Baptisia lactea"] <- "Baptisia alba"

deam6$speciesName[deam6$speciesName == "Lacinaria scariosa"] <- "Liatris scariosa"

deam6$speciesName[deam6$speciesName == "Carex striatula"] <- "Carex laxiflora"

deam6$speciesName[deam6$speciesName == "Viburnum pubescens"] <- "Viburnum dentatum"

deam6$speciesName[deam6$speciesName == "Celtis pumila"] <- "Celtis occidentalis"

deam6$speciesName[deam6$speciesName == "Vernonia altissima"] <- "Vernonia gigantea"

deam6$speciesName[grepl("Malus io", deam6$speciesName)] <- "Malus ioensis"

deam6$speciesName[deam6$speciesName == "Botrychium obliquum"] <- "Sceptridium dissectum"

deam6$speciesName[deam6$speciesName == "Arabis viridis"] <- "Borodinia missouriensis"

deam6$speciesName[grepl("tes engelmannii", deam6$speciesName)] <- "Isoetes engelmannii"

deam6$speciesName[deam6$speciesName == "Juncus macer"] <- "Juncus anthelatus"

deam6$speciesName[deam6$speciesName == "Solidago deamii"] <- "Solidago simplex"

deam6$speciesName[deam6$speciesName == "Rosa deamii"] <- "Rosa carolina"

deam6$speciesName[deam6$speciesName == "Panicum deamii"] <- "Dichanthelium ovale"

deam6$speciesName[deam6$speciesName == "Piptatherum pungens"] <- "Piptatheropsis pungens"

deam6$speciesName[deam6$speciesName == "Helianthus rigidus"] <- "Helianthus pauciflorus"

deam6$speciesName[deam6$speciesName == "Malus angustifolia"] <- "Malus ioensis"

deam6$speciesName[deam6$speciesName == "Stachys aff. tenuifolia"] <- "Stachys tenuifolia"

deam6$speciesName[deam6$speciesName == "Rubus satis"] <- "Rubus flagellaris"

# Remove remaining species not included on the official IND list

listhybrids <- c('Lacinaria deamii', 'Crataegus incaedua', 'Rubus profusiflorus', 'Tripleurospermum inodorum', 'Bromus briziformis', 'Rubus serratus', 'Ficus carica', 'Argemone mexicana')
deam7 <- deam6[ !grepl(paste(listhybrids, collapse="|"), deam6$speciesName),]

# Check species again
x <- deam7$speciesName %in% indspecies$ScientificName
y <- data.frame(x)
z <- data.frame(which(grepl("FALSE", y$x)))
```

## remove records of non-native species, using the list of non-native Indiana species located at: https://universalfqa.org/view_database/156. The dataframe "deam8" is the same as the data "Deam_Filtered_Data_10_31_2021."
```{r}
# load nonnatives list
nonnatives <- read.csv(file = "nonnatives_indiana.csv", header = T)
# remove species records that are non-native
deam <- deam7[ !grepl(paste(nonnatives$Scientific.Name, collapse="|"), deam7$speciesName),]
```

## Create site-species matrix for the complete dataset, treating counties as sites
```{r}
# Subset data to only include species name and county
sitesp1 <- subset(deam, select = c(county, speciesName))
# Sum number of occurrences of each species in each county
sitesp2 <- sitesp1 %>% count(county, speciesName)
# Create site x species matrix by reshaping data
sitesp <- pivot_wider(sitesp2, names_from = speciesName, values_from = n,)
# Replace NA's with 0
sitesp[is.na(sitesp)] <- 0
# convert back to data frame and name counties for sites. 
sitesp <- as.data.frame(sitesp)
rownames(sitesp) <- sitesp[,1]
sitesp <- sitesp[,-1]
```

## Calculate alpha diversity of native plant species per Indiana county using site-species matrix
```{r}
# write species richness function with site species matrix as input
S.obs <- function(x = ""){
  rowSums(x > 0) * 1
}
# calculate site species richness (county) using site species matrix of Indiana native species
obssprichwt <- data.frame(S.obs(sitesp))
colnames(obssprichwt)[1] <- "ALPHADIVERSITY"
# Set row header to new column
obssprichwt$county <- rownames(obssprichwt)
```

## Upload shapefile with Indiana counties
```{r warning=FALSE}
# upload shapefile with Indiana counties
indiana1 <- shapefile("~/Indiana PhD/IU--Applied Spatial Statistics/Course_Project/Indiana_Counties/Indiana_Counties.shp")
# change CRS to WGS84
indiana <- spTransform(indiana1, CRS=CRS("+proj=longlat +datum=WGS84"))
```

## Calculate species density per Indiana county land area
```{r}
# merge species richness with polygon data
spdensity <- merge(indiana,
                     obssprichwt,
                     by.x = "NAME",
                     by.y = "county")
# calculate square kilometers per county land area
spdensity$ALAND_KM2 <- spdensity$ALAND/1000000
# calculate ratio of species per square kilometer of land area for each county
spdensity$SPDENSITY_KM2 <- spdensity$ALPHADIVERSITY/spdensity$ALAND_KM2
```

## plot species density per Indiana county
```{r}
# plot using tmap
tm_shape(spdensity, projection="+init=epsg:4326") +
  tm_polygons("SPDENSITY_KM2", border.col = "grey30", title="Species Richness per km^2") + tm_compass(position=c("right", "top"), text.size = .5) + tm_layout(main.title = "Species Density per Indiana County Land Area", 
          main.title.size = .8, 
          main.title.fontface = 2, 
          legend.title.fontface = 2,
          legend.title.size = .6,
          title.position = c("center", "top"), 
          legend.text.size=.6, compass.type = "rose", inner.margins=c(.1,.1,.2,.4), aes.palette = list(seq = "-Spectral"), legend.outside = T, legend.position = c("right", "top")) + tm_scale_bar(size = 0.5)
```

## calculate correlation between county size and species richness
```{r}
# assess normality via histograms
hist(spdensity$ALAND, main = "Land Area per County", xlab = "Land Area (meters squared)", prob = T)
curve(dnorm(x,
            mean=mean(spdensity$ALAND),sd=sd(spdensity$ALAND)),
      col="darkblue", lwd=2, add=TRUE, yaxt="n")
lines(density(spdensity$ALAND), col="red")
hist(spdensity$ALPHADIVERSITY, main = "Species Richness per County", xlab = "Species Richness", prob = T)
curve(dnorm(x,
            mean=mean(spdensity$ALPHADIVERSITY),sd=sd(spdensity$ALPHADIVERSITY)),
      col="darkblue", lwd=2, add=TRUE, yaxt="n")
lines(density(spdensity$ALPHADIVERSITY), col="red")
# assess normality via qq plots
par(mfrow=c(1,2), pty='s', pch=19)
qqnorm(spdensity$ALAND, main = "Land Area per County", pch=19)
qqline(spdensity$ALAND)
qqnorm(spdensity$ALPHADIVERSITY, main = "Species Richness per County", pch=19)
qqline(spdensity$ALPHADIVERSITY)
# log both variables
spdensity$ALANDLOG <- log(spdensity$ALAND)
spdensity$ALPHADIVERSITYLOG <- log(spdensity$ALPHADIVERSITY)
# Reassess normality via qqplots
par(mfrow=c(1,2), pty='s', pch=19)
qqnorm(spdensity$ALANDLOG, main = "Land Area per County, logged", pch=19)
qqline(spdensity$ALANDLOG)
qqnorm(spdensity$ALPHADIVERSITYLOG, main = "Species Richness per County, logged", pch=19)
qqline(spdensity$ALPHADIVERSITYLOG)
# calculate pearson's correlation
rlog <- cor(spdensity$ALANDLOG, spdensity$ALPHADIVERSITYLOG, method = "pearson")
r <- cor(spdensity$ALAND, spdensity$ALPHADIVERSITY, method = "pearson")
```

### Part II: Import climate data
## import nc file containing climate data. Data is originally from: https://www.ncei.noaa.gov/data/nclimgrid-monthly/access/.
```{r}
# import data
climate1.brick <- brick("nclimgrid_tmin.nc")
# transform shapefile CRS to match raster CRS
indiana <- spTransform(indiana, crs(climate1.brick))
```

## subset raster data for study period and calculate a January layer by averaging January values into one raster layer
```{r}
# get layer names
layer_names <- names(climate1.brick)
# create vector of layer names to keep (January from 1896-1952)
years <- c(1896:1952)
layers_keep <- paste("X",years,".01",".01",sep="")
# keep layers if they contain 1896-1952
climate2.brick <- climate1.brick[[layers_keep]]
```

## mask raster data by Indiana shapefile
```{r}
climate.brick = mask(climate2.brick, indiana)
```

## calculate average minimum January temperature across Indiana per year
```{r}
# calculate average minimum January temperature per year
climate.average.year <- data.frame(rasterlayer.mean=cellStats(climate.brick, "mean"))
```

## plot time series of average minimum January temperature across Indiana per year
```{r}
plot(years,climate.average.year$rasterlayer.mean, type = "l", main = "Average January Minimum Temperature across Indiana", xlab = "Years (1896-1952)", ylab = "Average Minimum Temperature (C)", cex.main=0.9, cex.lab=0.9, xlim=c(1898,1950))
abline(lsfit(years, climate.average.year$rasterlayer.mean), col = "red")
year.fit = lm(climate.average.year$rasterlayer.mean~years)
summary(year.fit)
```

## average minimum average January temperatures per grid across study timeframe
```{r}
# calculate mean per grid and convert to raster
climate.average.grid <- mean(climate.brick)
```

## calculate average minimum January temperature per county
```{r}
# Extract raster values to list object
grid.raster.values <- raster::extract(climate.average.grid, indiana)
# Use list apply to calculate mean for each polygon
county.raster.values <- lapply(grid.raster.values, FUN=mean)
# list to dataframe
county.raster.values <- unlist(county.raster.values)
# Join mean values to polygon data
indiana$MEANMINAV <- county.raster.values
```

# plot mean January minimum temperatures per Indiana county
```{r}
# plot
tm_shape(indiana, projection="+init=epsg:4326") +
  tm_polygons("MEANMINAV", border.col = "grey30", title="Temperature (C)", n = 6) + tm_compass(position=c("right", "top"), text.size = .4) + tm_layout(main.title = "Mean Minimum January Temperature (1896-1952)", 
          main.title.size = .85, 
          main.title.fontface = 2, 
          legend.title.fontface = 2,
          legend.title.size = .95,
          title.position = c("center", "top"), 
          legend.text.size=.6, compass.type = "rose", inner.margins=c(.1,.1,.2,.4), aes.palette = list(seq = "-Spectral"), legend.outside = T, legend.position = c("right", "top")) + tm_scale_bar(size = 0.4)
```

### Part III: Calculate odds and conduct first Exact Multinomial Test
## create list of counties per segment
```{r}
# generate list of segment numbers
letters <- c("a", "b", "c", "d", "e", "f")
segments <- data.frame(paste(letters, "Climate Segment"))
colnames(segments)[1] <- "Segment"
# add segment column to indiana polygon data
indiana$SEGMENT <- cut(indiana$MEANMINAV, breaks=c(-4,-5,-6,-7,-8,-9,-10), labels=segments$Segment)
indiana$SEGMENT <- as.vector(indiana$SEGMENT)
# create dataframe with county and segment
countysegments <- data.frame(indiana$NAME)
colnames(countysegments)[1] <- "county"
countysegments$segment <- indiana$SEGMENT
```

# calculate the probability an occurrence happens in a county
```{r}
# calculate un-weighted chance of occurrence in each county
n <- length(indiana$ALAND)
indiana$UNWEIGHTEDCHANCE <- 1/n
# calculate weights based off of county land area
indiana$WEIGHTS <- indiana$ALAND / mean(indiana$ALAND)
# calculate weighted chance of occurrence in one county using area weights
indiana$WEIGHTEDCHANCE <- indiana$UNWEIGHTEDCHANCE * indiana$WEIGHTS
```

# calculate the probability an occurrence happens in a climate segment
```{r}
# sum county occurrences by climate segment to get the probabilities of an occurrence happening in any climate segment
climatesegmentprobs <- aggregate(WEIGHTEDCHANCE ~ SEGMENT, indiana, sum)
```

## Assign species data to counties and climate segments
```{r}
## Merge copy of ctydata and specdata
modela <- merge(countysegments, sitesp2, all.x = TRUE)
## Create new column with combined latitudinal segments and species
modela$climatesp <- paste(modela$segment, "Divide", modela$speciesName)
```

## Calculate counts of species per latitudinal segments
```{r}
## Create new column with occurence values (1)
modela$occval <- 1
## Sum occurences of species within climatic segments for observed model
modela2 <- aggregate(modela$occval, by=list(climatesp=modela$climatesp), FUN=sum)
colnames(modela2)[2] <- "count"
## Split column with latitudinal segments and species names
modela3 <- data.frame(str_split_fixed(modela2$climatesp, "Divide", 2))
modela3$count <- modela2$count
colnames(modela3)[1] <- "climateSegment"
colnames(modela3)[2] <- "speciesName"
```

## Add 0's for species that do not occur in specific latitudinal segments
```{r}
## Construct dataframe with a latitudinal segment for each species and a column of 0's
speciesnames <- data.frame(unique(modela$speciesName))
colnames(speciesnames)[1] <- "speciesName"
y <- length(speciesnames$speciesName)
climatesegs <- data.frame(unique(modela3$climateSegment))
colnames(climatesegs)[1] <- "climateSegs"
z <- length(climatesegs$climateSegs)
climatesegs2 <- do.call("rbind", replicate(y, climatesegs, simplify = FALSE))
speciesnames2 <- do.call("rbind", replicate(z, speciesnames, simplify = FALSE))
speciesnames3 <- data.frame(speciesnames2[order(speciesnames2$speciesName),])
colnames(speciesnames3)[1] <- "species"
climatesegs2$species <- speciesnames3$species
climatesegs2$zero <- 0
## Re-order counts of species within latitudinal segments by species and insert "l" in latitude column
modela4 <- data.frame(modela3[order(modela3$speciesName, modela3$climateSegment),])
modela4$climateseg2 <- paste(modela4$climateSegment,modela4$c, sep ="")
## Keep only desired columns and rename columns appropriately between climateseg2 and modela4
modela5 <- subset(modela4, select = c(speciesName, count, climateseg2))
colnames(modela5)[3] <- "climateseg"
colnames(climatesegs2) <- c("climateseg", "speciesName", "count")
## Insert 0 for climate seg occurences with no records
climatesegsc <- data.frame(unique(modela5$climateseg))
colnames(climatesegsc)[1] <- "climateseg"
modela6 <- complete(modela5, climatesegsc, speciesName, fill = list(count = 0))
# Reorder data by climate segments
modela7 <- modela6[with(modela6, order(speciesName, climateseg)), ]
```

## prepare data for exact multinomial test
```{r}
## Count number of species
z <- length(speciesnames$speciesName)
## Group counts by species
modela8 <- subset(modela7, select = c(speciesName, count))
modela9 <- modela8 %>% group_by(speciesName) %>% summarize(speciesCount = list(count))
## Create empty vector for p-values
pvalues1 <- array(c(0), dim = z)
## Create list of vectors, with each vector containing counts of species
modela10 <- (as.vector(modela9$speciesCount))
```

## Conduct Exact Multinomial Test
```{r}
## Conduct exact multinomial test and output p-values for each species
set.seed(1)
for(i in 1:z){
  pvalues1[i] = 
multinomial.test(modela10[[i]], climatesegmentprobs$WEIGHTEDCHANCE, useChisq = TRUE)$p.value}
```

## Set vector of p-values as dataframe, insert species names, and correct p-values for using same dataframe
```{r}
## Set vector of p-values as dataframe
pvalues2 <- as.data.frame(pvalues1)
## Insert species names and pair with corresponding p-values
pvalues2$speciesName <- modela9$speciesName
## Correct p-values by false discovery rate
pvalues2$padj = p.adjust(pvalues2$pvalues1, method="fdr")
write.csv(pvalues2, "preliminaryresults.csv")
```




